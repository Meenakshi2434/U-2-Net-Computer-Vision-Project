{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1c99OaEFMIqGRaFnpbVHXFOaOpyAYbnj1","authorship_tag":"ABX9TyMye8XA9GzHQ3hrIDLwpcXT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oA3gZmLYgeMQ","collapsed":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import numpy as np\n","import cv2\n","import glob\n","import os\n","import random\n","\n","\n","# Define the data transforms\n","transform_image = transforms.Compose([\n","    transforms.Resize((320, 320)),  # Resize to 320x320\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalize RGB image\n","])\n","\n","transform_mask = transforms.Compose([\n","    transforms.Resize((320, 320)),  # Resize to 320x320\n","    transforms.ToTensor() # Convert mask to tensor, no normalization\n","])\n","\n","# Load the dataset\n","image_folder = '/content/drive/MyDrive/Image'\n","mask_folder = '/content/drive/MyDrive/Mask'\n","\n","image_paths = glob.glob(os.path.join(image_folder, '*.jpg'))\n","mask_paths = glob.glob(os.path.join(mask_folder, '*.png'))\n","\n","# Split the data into training and validation sets (80% for training, 20% for validation)\n","train_size = int(0.8 * len(image_paths))\n","val_size = len(image_paths) - train_size\n","\n","train_indices = random.sample(range(len(image_paths)), train_size)\n","val_indices = [i for i in range(len(image_paths)) if i not in train_indices]\n","\n","train_image_paths = [image_paths[i] for i in train_indices]\n","train_mask_paths = [mask_paths[i] for i in train_indices]\n","val_image_paths = [image_paths[i] for i in val_indices]\n","val_mask_paths = [mask_paths[i] for i in val_indices]\n","# Define the custom dataset class for our data\n","class CarDataset(Dataset):\n","    def __init__(self, image_paths, mask_paths, transform=None, target_transform=None): # Add target_transform parameter\n","        self.image_paths = image_paths\n","        self.mask_paths = mask_paths\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.image_paths[idx])\n","        mask = Image.open(self.mask_paths[idx])\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            mask = self.target_transform(mask) # Apply target transform to mask\n","        mask = mask.unsqueeze(0)  # Add a channel dimension to the target tensor\n","        return image, mask\n","\n","# Create data loaders for training and validation\n","train_dataset = CarDataset(train_image_paths, train_mask_paths, transform=transform_image, target_transform=transform_mask) # Apply different transforms to images and masks\n","val_dataset = CarDataset(val_image_paths, val_mask_paths, transform=transform_image, target_transform=transform_mask)\n","\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","\n","# Define the U-Net model\n","class U2Net(nn.Module):\n","    def __init__(self):\n","        super(U2Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n","        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)\n","        self.conv5 = nn.Conv2d(128, 256, kernel_size=3)\n","        self.conv6 = nn.Conv2d(256, 256, kernel_size=3)\n","        self.conv7 = nn.Conv2d(256, 512, kernel_size=3)\n","        self.conv8 = nn.Conv2d(512, 512, kernel_size=3)\n","        self.conv9 = nn.Conv2d(512, 256, kernel_size=3)\n","        self.conv10 = nn.Conv2d(256, 256, kernel_size=3)\n","        self.conv11 = nn.Conv2d(256, 128, kernel_size=3)\n","        self.conv12 = nn.Conv2d(128, 128, kernel_size=3)\n","        self.conv13 = nn.Conv2d(128, 64, kernel_size=3)\n","        self.conv14 = nn.Conv2d(64, 64, kernel_size=3)\n","        self.conv15 = nn.Conv2d(64, 3, kernel_size=3)  # Output 3 channels\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = torch.relu(self.conv2(x))\n","        x = torch.relu(self.conv3(x))\n","        x = torch.relu(self.conv4(x))\n","        x = torch.relu(self.conv5(x))\n","        x = torch.relu(self.conv6(x))\n","        x = torch.relu(self.conv7(x))\n","        x = torch.relu(self.conv8(x))\n","        x = torch.relu(self.conv9(x))\n","        x = torch.relu(self.conv10(x))\n","        x = torch.relu(self.conv11(x))\n","        x = torch.relu(self.conv12(x))\n","        x = torch.relu(self.conv13(x))\n","        x = torch.relu(self.conv14(x))\n","        x = torch.sigmoid(self.conv15(x))  # Output shape: [batch_size, 3, 320, 320]\n","        return x.unsqueeze(0)  # Add a batch dimension\n","\n","# Define the dice loss function\n","def dice_loss(pred, target):\n","    smooth = 1.0\n","    pred = pred[:, 0, :, :]  # Select the first channel\n","    target = target[:, 0, :, :]  # Select the first channel\n","    intersection = (pred * target).sum(dim=(1, 2))\n","    union = pred.sum(dim=(1, 2)) + target.sum(dim=(1, 2))\n","    dice = (2 * intersection + smooth) / (union + smooth)\n","    return 1 - dice.mean()\n","\n","# Define the IoU metric\n","def iou_score(pred, target):\n","    pred = (pred > 0.5).float()\n","    target = (target > 0.5).float()\n","    intersection = (pred * target).sum()\n","    union = (pred + target).sum() - intersection\n","    return (intersection + 1) / (union + 1)\n","\n","# Initialize the model, optimizer, and loss function\n","model = U2Net()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = dice_loss\n","\n","# Train the model\n","for epoch in range(5):\n","    model.train()\n","    for batch in train_loader:\n","        images, masks = batch\n","        images, masks = images.to(device), masks.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            images, masks = batch\n","            images, masks = images.to(device), masks.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, masks)\n","            total_loss += loss.item()\n","    print(f'Epoch {epoch+1}, Val Loss: {total_loss / len(val_loader)}')\n","\n","# Evaluate the model on the validation set\n","model.eval()\n","total_iou = 0\n","with torch.no_grad():\n","    for batch in val_loader:\n","        images, masks = batch\n","        images, masks = images.to(device), masks.to(device)\n","        outputs = model(images)\n","        iou = iou_score(outputs, masks)\n","        total_iou += iou.item()\n","print(f'Val IoU: {total_iou / len(val_loader)}')"]}]}